name: "02 • Quality Analysis"

on:
  workflow_run:
    workflows: ["01 • Build & Test"]
    types:
      - completed
  workflow_dispatch:
    inputs:
      pr-number:
        description: 'Pull request number'
        required: false
        type: string

permissions:
  id-token: write
  contents: read
  actions: read
  pull-requests: write
  issues: write
  checks: write

jobs:
  quality-analysis:
    name: "Quality Analysis"
    runs-on: ubuntu-latest
    if: always() && (github.event.workflow_run.event == 'pull_request' || github.event_name == 'workflow_dispatch')
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup development environment
        uses: ./.github/actions/shared/setup-environment
        with:
          setup-dotnet: 'true'
          setup-node: 'false'
          dotnet-version: '8.0.x'

      - name: Get PR Number
        id: pr-number
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ -n "${{ github.event.inputs.pr-number }}" ]; then
            # Manual dispatch with PR number
            PR_NUMBER="${{ github.event.inputs.pr-number }}"
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            # Direct PR trigger
            PR_NUMBER="${{ github.event.number }}"
          else
            # workflow_run trigger - extract PR number
            PR_NUMBER=$(gh run view ${{ github.event.workflow_run.id }} --json headBranch | jq -r '.headBranch' | grep -o 'pull/[0-9]*' | cut -d'/' -f2 || echo "")
            if [ -z "$PR_NUMBER" ]; then
              # Alternative: get PR number from API using commit SHA
              PR_NUMBER=$(gh api repos/${{ github.repository }}/pulls --jq ".[] | select(.head.sha==\"${{ github.event.workflow_run.head_sha }}\") | .number")
            fi
          fi
          echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
          echo "Found PR number: $PR_NUMBER"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create PR check run
        id: create-check
        if: steps.pr-number.outputs.pr_number != ''
        run: |
          CHECK_RUN_ID=$(gh api repos/${{ github.repository }}/check-runs \
            --method POST \
            --field name="Quality Analysis" \
            --field head_sha="${{ github.event.workflow_run.head_sha || github.sha }}" \
            --field status="in_progress" \
            --field details_url="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --jq '.id')
          echo "check_run_id=$CHECK_RUN_ID" >> $GITHUB_OUTPUT
          echo "Created check run ID: $CHECK_RUN_ID"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Download test results
        if: github.event_name == 'workflow_run'
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: test-results-${{ github.event.workflow_run.run_number }}
          path: ./
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Run quality checks
        id: quality-checks
        shell: bash
        run: |
          echo "🔍 Running comprehensive quality analysis..."
          
          # Set environment variables
          export PR_NUMBER="${{ steps.pr-number.outputs.pr_number }}"
          export BASE_BRANCH="${{ github.event.workflow_run.pull_requests[0].base.ref || 'develop' }}"
          export HEAD_SHA="${{ github.event.workflow_run.head_sha || github.sha }}"
          export CLAUDE_CODE_OAUTH_TOKEN="${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}"
          export GITHUB_TOKEN="${{ secrets.GITHUB_TOKEN }}"
          
          # Debug information
          echo "Debug: PR_NUMBER=$PR_NUMBER"
          echo "Debug: BASE_BRANCH=$BASE_BRANCH"
          echo "Debug: HEAD_SHA=$HEAD_SHA"
          echo "Debug: Current directory: $(pwd)"
          echo "Debug: Script exists: $(ls -la ./Scripts/Pipeline/run-quality-checks.sh)"
          
          # Make scripts executable and execute quality analysis
          chmod +x ./Scripts/Pipeline/run-quality-checks.sh
          chmod +x ./Scripts/Pipeline/*.sh
          
          # Execute with proper parameter handling
          if [ -n "$PR_NUMBER" ]; then
            ./Scripts/Pipeline/run-quality-checks.sh \
              --pr-number "$PR_NUMBER" \
              --base-branch "$BASE_BRANCH" \
              --head-sha "$HEAD_SHA" \
              --severity medium
          else
            ./Scripts/Pipeline/run-quality-checks.sh \
              --base-branch "$BASE_BRANCH" \
              --head-sha "$HEAD_SHA" \
              --severity medium
          fi

      - name: Standards Compliance AI Analysis
        if: steps.pr-number.outputs.pr_number != ''
        id: claude-standards
        uses: anthropics/claude-code-base-action@beta
        continue-on-error: true
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          prompt_file: Scripts/Prompts/standards-compliance.md
          allowed_tools: "Read,Glob,Grep,Bash"
          timeout_minutes: 5

      - name: Tech Debt AI Analysis  
        if: steps.pr-number.outputs.pr_number != ''
        id: claude-techdebt
        uses: anthropics/claude-code-base-action@beta
        continue-on-error: true
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          prompt_file: Scripts/Prompts/tech-debt-analysis.md
          allowed_tools: "Read,Glob,Grep,Bash"
          timeout_minutes: 5

      - name: Post Standards Compliance Comment
        if: always() && steps.pr-number.outputs.pr_number != '' && steps.claude-standards.outcome == 'success'
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            try {
              const executionFile = '${{ steps.claude-standards.outputs.execution_file || '' }}';
              if (executionFile && fs.existsSync(executionFile)) {
                const executionLog = JSON.parse(fs.readFileSync(executionFile, 'utf8'));
                const analysis = executionLog
                  .filter(entry => entry.role === 'assistant' && entry.content)
                  .map(entry => entry.content)
                  .join('\n\n');
                
                if (analysis) {
                  await github.rest.issues.createComment({
                    issue_number: ${{ steps.pr-number.outputs.pr_number }},
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    body: "## 🛠️ Standards Compliance Analysis\\n\\n" + analysis
                  });
                }
              }
            } catch (error) {
              console.log('Could not post standards compliance comment:', error.message);
            }

      - name: Post Tech Debt Comment
        if: always() && steps.pr-number.outputs.pr_number != '' && steps.claude-techdebt.outcome == 'success'
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            try {
              const executionFile = '${{ steps.claude-techdebt.outputs.execution_file || '' }}';
              if (executionFile && fs.existsSync(executionFile)) {
                const executionLog = JSON.parse(fs.readFileSync(executionFile, 'utf8'));
                const analysis = executionLog
                  .filter(entry => entry.role === 'assistant' && entry.content)
                  .map(entry => entry.content)
                  .join('\n\n');
                
                if (analysis) {
                  await github.rest.issues.createComment({
                    issue_number: ${{ steps.pr-number.outputs.pr_number }},
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    body: "## 📈 Tech Debt Analysis\\n\\n" + analysis
                  });
                }
              }
            } catch (error) {
              console.log('Could not post tech debt comment:', error.message);
            }


      - name: Quality metrics summary
        run: |
          SCORE="${{ steps.quality-checks.outputs.overall_score }}"
          VIOLATIONS="${{ steps.quality-checks.outputs.standards_violations }}"
          DEBT_ITEMS="${{ steps.quality-checks.outputs.tech_debt_items }}"
          
          echo "📊 Quality Analysis Summary"
          echo "Overall quality score: ${SCORE:-0}/100"
          echo "Standards violations: ${VIOLATIONS:-0}"
          echo "Tech debt items: ${DEBT_ITEMS:-0}"
          echo ""
          
          if [[ "${SCORE:-0}" -lt 70 ]]; then
            echo "⚠️  Quality score below optimal threshold (70)"
            echo "🤖 Claude AI analysis posted with standards compliance insights"
            echo "🤖 Claude AI analysis posted with tech debt recommendations"
            echo "🎯 This is informational - see PR comments for actionable insights"
          else
            echo "✅ Quality score meets threshold"
            echo "🤖 Claude AI analysis available with optimization recommendations"
          fi
          
          echo ""
          echo "📝 Real Claude AI analysis available in separate PR comments"

      - name: Create quality issues
        if: always() && steps.quality-checks.outputs.tech_debt_items > 10
        uses: ./.github/actions/create-tech-debt-issues
        continue-on-error: true
        with:
          pr-number: ${{ steps.pr-number.outputs.pr_number }}
          quality-data-file: artifacts/quality/quality-analysis-data.json
          github-token: ${{ secrets.GITHUB_TOKEN }}

      - name: Complete PR check run
        if: always() && steps.create-check.outputs.check_run_id != ''
        run: |
          # Quality analysis is informational - only fail on technical errors
          SCORE="${{ steps.quality-checks.outputs.overall_score }}"
          
          if [ "${{ job.status }}" = "success" ]; then
            if [[ "${SCORE:-0}" -lt 70 ]]; then
              CONCLUSION="neutral"
              TITLE="📊 Quality Analysis: Insights Available"
              SUMMARY="Quality score: ${SCORE:-0}/100. AI recommendations posted to PR comments."
            else
              CONCLUSION="success"
              TITLE="✅ Quality Analysis: Excellent Quality"
              SUMMARY="Quality score: ${SCORE:-0}/100. Code meets quality standards."
            fi
          elif [ "${{ job.status }}" = "failure" ]; then
            CONCLUSION="failure"
            TITLE="❌ Quality Analysis: Technical Error"
            SUMMARY="Quality analysis failed due to technical issues - check workflow logs"
          else
            CONCLUSION="neutral"
            TITLE="📊 Quality Analysis: Completed"
            SUMMARY="Quality analysis completed. Results available in PR comments."
          fi
          
          gh api repos/${{ github.repository }}/check-runs/${{ steps.create-check.outputs.check_run_id }} \
            --method PATCH \
            --field status="completed" \
            --field conclusion="$CONCLUSION" \
            --field output[title]="$TITLE" \
            --field output[summary]="$SUMMARY"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload quality artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-analysis-${{ github.run_number }}
          path: artifacts/quality/
          retention-days: 30

  quality-summary:
    name: "Quality Summary"
    runs-on: ubuntu-latest
    needs: quality-analysis
    if: always() && !cancelled()
    
    steps:
      - name: Generate quality summary
        run: |
          echo "📊 Quality Analysis Summary"
          echo "=========================="
          echo ""
          echo "**Analysis Results:**"
          echo "  - Quality analysis: ${{ needs.quality-analysis.result }}"
          echo ""
          
          if [ "${{ needs.quality-analysis.result }}" = "failure" ]; then
            echo "❌ Quality analysis failed due to technical issues"
            echo "🔧 Check workflow logs for technical problems"
          elif [ "${{ needs.quality-analysis.result }}" = "success" ]; then
            echo "✅ Quality analysis completed successfully"
            echo "🤖 Claude AI standards compliance analysis posted to PR"
            echo "🤖 Claude AI tech debt analysis posted to PR"
            echo "📊 Real AI-powered insights and recommendations available in PR comments"
          else
            echo "⚠️ Quality analysis was skipped or cancelled"
          fi
          
          echo ""
          echo "ℹ️  Note: Quality analysis is informational and provides real Claude AI-powered"
          echo "   recommendations for code improvement. It does not block deployments."
          echo "🤖 Claude AI provides separate detailed analysis for standards compliance and tech debt."