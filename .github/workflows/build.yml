name: "Build & Test"

# Epic #181 Build Workflows Enhancement - Canonical Foundation Component Integration
# Issue #212: Refactored to consume foundation components from Issue #183
#
# Foundation Components Integrated:
# - ./.github/actions/shared/path-analysis: Intelligent change detection (replaces lines 57-68)
# - ./.github/actions/shared/backend-build: Standardized .NET build with coverage flexibility (replaces lines 116-189)
#
# Behavioral Parity Guarantee:
# All existing triggers, permissions, concurrency, branch logic, and AI integration preserved
# Job outputs maintain exact interface compatibility for downstream dependencies
# Zero-warning policy enforcement and coverage flexibility logic unchanged
#
# Canonical Pattern for Issue #184:
# This refactored workflow demonstrates the standard approach for consuming foundation components
# while preserving exact behavioral parity through interface mapping and legacy compatibility layers

on:
  push:
    branches: [main, develop]
    paths:
      - 'Code/**'
      - '.github/scripts/**'
      - '*.sln'
      - '.github/workflows/**'
      - '.github/actions/shared/**'
  pull_request:
    branches: ['**']  # Trigger on ALL branch targets for universal PR support
    paths:
      - 'Code/**'
      - '.github/scripts/**'
      - '*.sln'
      - '.github/workflows/**'
      - '.github/actions/shared/**'
  workflow_dispatch:

# Concurrency Configuration: Workflow-level (not foundation component)
# Foundation components provide behavior, not policy - concurrency remains at workflow level
# Pattern Reference: concurrency-config foundation component documents best practices
# but actual concurrency is defined here for workflow-specific coordination
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}  # Standard pattern for main build workflows
  cancel-in-progress: true                          # Resource optimization during rapid development

env:
  DOTNET_VERSION: '8.0.x'
  NODE_VERSION: '18.x'

permissions:
  id-token: write
  contents: read
  actions: read
  pull-requests: write
  issues: write
  checks: write
  security-events: write

jobs:
  path-analysis:
    name: "Analyze Changed Paths"
    runs-on: ubuntu-latest
    outputs:
      # Preserved output interface for downstream job compatibility
      backend-changed: ${{ steps.map-outputs.outputs.backend-changed }}
      frontend-changed: ${{ steps.map-outputs.outputs.frontend-changed }}
      docs-only: ${{ steps.map-outputs.outputs.docs-only }}
      changed-files: ${{ steps.map-outputs.outputs.changed-files }}
      tests-changed: ${{ steps.map-outputs.outputs.tests-changed }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Foundation Component Integration: path-analysis (Issue #183)
      # Replaces inline base reference determination logic (lines 57-68)
      - name: Execute path analysis with foundation component
        id: foundation-path-analysis
        uses: ./.github/actions/shared/path-analysis
        # Note: base_ref determination handled internally by foundation component

      # Output Mapping: Foundation component -> build.yml interface
      # Ensures exact behavioral parity with existing downstream jobs
      - name: Map foundation outputs to build.yml interface
        id: map-outputs
        run: |
          # Map foundation component outputs to existing build.yml interface
          echo "backend-changed=${{ steps.foundation-path-analysis.outputs.has_backend_changes }}" >> $GITHUB_OUTPUT
          echo "frontend-changed=${{ steps.foundation-path-analysis.outputs.has_frontend_changes }}" >> $GITHUB_OUTPUT

          # Extract change data from foundation's change_summary JSON for proper behavioral parity
          CHANGE_SUMMARY='${{ steps.foundation-path-analysis.outputs.change_summary }}'

          # Extract tests-changed from change_summary JSON (missing output fix)
          TESTS_CHANGED=$(echo "$CHANGE_SUMMARY" | jq -r '.categories.tests.changed // false')
          echo "tests-changed=$TESTS_CHANGED" >> $GITHUB_OUTPUT

          # Calculate docs-only correctly (docs changed AND nothing else changed) - exclusive semantics fix
          DOCS=$(echo "$CHANGE_SUMMARY" | jq -r '.categories.documentation.changed // false')
          BACKEND="${{ steps.foundation-path-analysis.outputs.has_backend_changes }}"
          FRONTEND="${{ steps.foundation-path-analysis.outputs.has_frontend_changes }}"
          CONFIG="${{ steps.foundation-path-analysis.outputs.has_config_changes }}"

          # docs-only is true when ONLY docs changed (exclusive semantics)
          if [[ "$DOCS" == "true" && "$BACKEND" == "false" && "$FRONTEND" == "false" && "$TESTS_CHANGED" == "false" && "$CONFIG" == "false" ]]; then
            DOCS_ONLY="true"
          else
            DOCS_ONLY="false"
          fi
          echo "docs-only=$DOCS_ONLY" >> $GITHUB_OUTPUT

          # Preserve existing changed-files interface using foundation's outputs
          COMPONENTS=""
          if [[ "${{ steps.foundation-path-analysis.outputs.has_backend_changes }}" == "true" ]]; then
            COMPONENTS="backend"
          fi
          if [[ "${{ steps.foundation-path-analysis.outputs.has_frontend_changes }}" == "true" ]]; then
            COMPONENTS="$COMPONENTS frontend"
          fi
          if [[ "$DOCS" == "true" ]]; then
            COMPONENTS="$COMPONENTS docs"
          fi
          if [[ "$TESTS_CHANGED" == "true" ]]; then
            COMPONENTS="$COMPONENTS tests"
          fi
          if [[ "${{ steps.foundation-path-analysis.outputs.has_config_changes }}" == "true" ]]; then
            COMPONENTS="$COMPONENTS config"
          fi
          # Clean up and format as comma-separated list
          COMPONENTS=$(echo "$COMPONENTS" | sed 's/^ *//' | sed 's/ /,/g')
          echo "changed-files=$COMPONENTS" >> $GITHUB_OUTPUT

      - name: Display path analysis
        run: |
          echo "🔍 Path Analysis Results (Foundation Component):"
          echo "  - Backend changed: ${{ steps.map-outputs.outputs.backend-changed }}"
          echo "  - Frontend changed: ${{ steps.map-outputs.outputs.frontend-changed }}"
          echo "  - Tests changed: ${{ steps.map-outputs.outputs.tests-changed }}"
          echo "  - Documentation only: ${{ steps.map-outputs.outputs.docs-only }}"
          echo "  - Changed components: ${{ steps.map-outputs.outputs.changed-files }}"
          echo "  - Foundation summary: ${{ steps.foundation-path-analysis.outputs.total_changes }} total changes"
          echo "  - Test run: End-to-end validation"

  ai-headers-check:
    name: "AI Headers • Contract Check"
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'pull_request' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate canonical AI header keys
        run: |
          ./.github/scripts/validate-ai-headers.sh

  backend-build:
    name: "Backend • Build & Test"
    runs-on: ubuntu-latest
    needs: path-analysis
    # Run backend build when backend code OR tests changed
    if: needs.path-analysis.outputs.backend-changed == 'true' || needs.path-analysis.outputs.tests-changed == 'true'
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Foundation Component Integration: backend-build (Issue #183)
      # Replaces duplicated build execution logic (lines 116-189) with standardized component
      # Preserves all existing behavior: coverage flexibility, zero-warning enforcement, artifact management
      - name: Execute backend build with foundation component
        id: foundation-backend-build
        uses: ./.github/actions/shared/backend-build
        with:
          # Preserve existing configuration
          solution_path: 'zarichney-api.sln'
          coverage_enabled: 'true'  # Always collect coverage data
          warning_as_error: 'true'  # Preserve zero-warning policy
          configuration: 'Release'
          verbosity: 'normal'
          # Note: Coverage flexibility logic is handled internally by foundation component

      # Legacy Interface Mapping: Foundation outputs -> existing build.yml expectations
      # Ensures downstream jobs (annotations, AI analysis) continue working unchanged
      - name: Map foundation outputs to legacy interface
        if: always()
        id: backend-execution
        run: |
          # Map foundation component outputs to existing interface for downstream compatibility
          echo "build_success=${{ steps.foundation-backend-build.outputs.build_success }}" >> $GITHUB_OUTPUT
          echo "warning_count=${{ steps.foundation-backend-build.outputs.warning_count }}" >> $GITHUB_OUTPUT
          echo "test_success=${{ steps.foundation-backend-build.outputs.test_success }}" >> $GITHUB_OUTPUT
          echo "coverage_percentage=${{ steps.foundation-backend-build.outputs.coverage_percentage }}" >> $GITHUB_OUTPUT

          # Map error handling outputs for annotation step compatibility
          ERROR_DETAILS='${{ steps.foundation-backend-build.outputs.error_details }}'
          if [[ "${{ steps.foundation-backend-build.outputs.build_success }}" == "false" ]]; then
            # Analyze error details to determine failure type (preserves existing annotation logic)
            if echo "$ERROR_DETAILS" | grep -qi "warning.*treated as error"; then
              echo "build_failure_type=warnings" >> $GITHUB_OUTPUT
              echo "warning_enforcement_active=true" >> $GITHUB_OUTPUT
            elif echo "$ERROR_DETAILS" | grep -qi "error"; then
              echo "build_failure_type=compilation" >> $GITHUB_OUTPUT
              echo "warning_enforcement_active=true" >> $GITHUB_OUTPUT
            else
              echo "build_failure_type=unknown" >> $GITHUB_OUTPUT
              echo "warning_enforcement_active=true" >> $GITHUB_OUTPUT
            fi
          else
            echo "warning_enforcement_active=true" >> $GITHUB_OUTPUT
          fi

          # Display foundation component results
          echo "🚀 Backend Build Results (Foundation Component):"
          echo "  - Build success: ${{ steps.foundation-backend-build.outputs.build_success }}"
          echo "  - Test success: ${{ steps.foundation-backend-build.outputs.test_success }}"
          echo "  - Warning count: ${{ steps.foundation-backend-build.outputs.warning_count }}"
          echo "  - Coverage: ${{ steps.foundation-backend-build.outputs.coverage_percentage }}%"

      # Preserved Annotation Logic: Exact behavioral parity with existing build.yml
      # All downstream steps remain unchanged to ensure zero behavioral drift
      - name: Annotate backend build failures
        if: failure() && steps.foundation-backend-build.outcome == 'failure'
        run: |
          echo "📊 Analyzing backend build failure for warning-related issues..."

          # Check if build failure was due to warnings
          if [[ "${{ steps.backend-execution.outputs.build_failure_type }}" == "warnings" ]]; then
            echo "::error title=Backend Build Failed - Warnings Detected::Zero-warning policy enforced: MSBuild TreatWarningsAsErrors=true caused build failure. Fix all compiler warnings before proceeding."
            echo "::notice title=Warning Enforcement Active::This build uses zero-tolerance warning policy. All compiler warnings must be resolved."
          elif [[ "${{ steps.backend-execution.outputs.build_failure_type }}" == "compilation" ]]; then
            echo "::error title=Backend Build Failed - Compilation Errors::Fix compilation errors in .NET codebase before proceeding."
          else
            echo "::error title=Backend Build Failed::Unknown build failure - check build logs for details."
          fi

          # Summary annotation
          echo "::notice title=Zero-Warning Build Policy::This project enforces zero compiler warnings. Warning-as-error enforcement: ${{ steps.backend-execution.outputs.warning_enforcement_active }}"

      # Note: Artifact upload and test validation steps are handled by foundation component
      # Foundation component automatically uploads artifacts and performs test validation
      # This preserves all existing behavior while reducing duplication

  # AI Sentinel Integration: Preserved Unchanged
  # All 5 AI Sentinels (DebtSentinel, StandardsGuardian, TestMaster, SecuritySentinel, MergeOrchestrator)
  # continue functioning identically despite foundation component refactor
  # Job dependencies and conditional logic remain exactly as before
  claude-testing-analysis:
    name: "Quality Analysis • Testing Analysis (AI)"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build, build-summary]
    if: always() && !cancelled() && github.event_name == 'pull_request' && contains(fromJSON('["main", "develop"]'), github.event.pull_request.base.ref) && (needs.build-summary.result == 'success' || needs.path-analysis.outputs.docs-only == 'true')
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Extract PR Context
        id: pr-context
        uses: ./.github/actions/shared/extract-pr-context

      - name: Download test results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: test-results-${{ github.run_number }}
          path: ./

      - name: Check for existing Testing analysis comment
        id: check-existing-comment
        uses: ./.github/actions/shared/check-existing-comment
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          header: '## Code Review Report - Testing Analysis'

      - name: Create skip status check
        if: steps.check-existing-comment.outputs.skip_analysis == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('TestMaster analysis skipped - existing unresolved analysis comment found');

      - name: Load testing analysis prompt
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: load-testing-prompt
        run: |
          # Read the markdown template
          PROMPT_TEMPLATE=$(cat .github/prompts/testing-analysis.md)

          # Replace placeholders with actual values
          PROMPT="${PROMPT_TEMPLATE//\{\{PR_NUMBER\}\}/${{ github.event.number }}}"
          PROMPT="${PROMPT//\{\{PR_AUTHOR\}\}/${{ github.event.pull_request.user.login }}}"
          PROMPT="${PROMPT//\{\{ISSUE_REF\}\}/${{ steps.pr-context.outputs.issue_ref }}}"
          PROMPT="${PROMPT//\{\{SOURCE_BRANCH\}\}/${{ github.event.pull_request.head.ref }}}"
          PROMPT="${PROMPT//\{\{TARGET_BRANCH\}\}/${{ github.event.pull_request.base.ref }}}"
          PROMPT="${PROMPT//\{\{CHANGED_FILES_COUNT\}\}/${{ steps.pr-context.outputs.changed_files_count }}}"
          PROMPT="${PROMPT//\{\{LINES_CHANGED\}\}/${{ steps.pr-context.outputs.lines_changed }}}"

          # Output for use in Claude action
          echo "prompt<<EOF" >> $GITHUB_OUTPUT
          echo "$PROMPT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Testing Analysis with Claude AI
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: claude-testing
        uses: grll/claude-code-action@beta
        with:
          use_oauth: true
          claude_access_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          claude_refresh_token: ${{ secrets.CLAUDE_REFRESH_TOKEN }}
          claude_expires_at: ${{ secrets.CLAUDE_EXPIRES_AT }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          direct_prompt: ${{ steps.load-testing-prompt.outputs.prompt }}

      - name: Handle Claude AI Failure
        if: failure() && steps.claude-testing.outcome == 'failure'
        uses: ./.github/actions/handle-ai-analysis-failure
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          analysis-type: 'TestMaster'
          analysis-emoji: '🧪'
          analysis-name: 'Testing Analysis'
          standards-link: 'https://github.com/Zarichney-Development/zarichney-api/blob/main/Docs/Standards/TestingStandards.md'
          run-number: ${{ github.run_number }}
          run-id: ${{ github.run_id }}

  frontend-build:
    name: "Frontend • Build & Test"
    runs-on: ubuntu-latest
    needs: path-analysis
    if: needs.path-analysis.outputs.frontend-changed == 'true'
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup development environment
        uses: ./.github/actions/shared/setup-environment
        with:
          setup-dotnet: 'false'
          setup-node: 'true'
          node-version: ${{ env.NODE_VERSION }}

      - name: Execute frontend build and test
        id: frontend-execution
        run: |
          echo "🚀 Running frontend build and test pipeline..."
          echo "⚠️  Warning Enforcement: ESLint --max-warnings=0 (zero-tolerance policy)"

          # Set CI environment variables
          export CI_ENVIRONMENT=true

          # Execute the pipeline script
          ./.github/scripts/build-frontend.sh --prod

      - name: Annotate frontend build failures
        if: failure() && steps.frontend-execution.outcome == 'failure'
        run: |
          echo "📊 Analyzing frontend build failure for warning-related issues..."

          # Check if build failure was due to warnings
          if [[ "${{ steps.frontend-execution.outputs.lint_failure_type }}" == "warnings" ]]; then
            echo "::error title=Frontend Build Failed - ESLint Warnings Detected::Zero-warning policy enforced: ESLint --max-warnings=0 caused build failure. Fix all linting warnings before proceeding."
            echo "::notice title=ESLint Warning Count::${{ steps.frontend-execution.outputs.eslint_warning_count }} warnings detected"
            echo "::notice title=Warning Enforcement Active::This build uses zero-tolerance ESLint warning policy. All warnings must be resolved."
          elif [[ "${{ steps.frontend-execution.outputs.lint_failure_type }}" == "configuration" ]]; then
            echo "::error title=Frontend Build Failed - ESLint Configuration Error::Fix ESLint configuration issues before proceeding."
          elif [[ "${{ steps.frontend-execution.outputs.lint_failure_type }}" == "basic" ]]; then
            echo "::warning title=Frontend Build Failed - Basic Linting Issues::Using fallback lint script. Consider implementing lint:ci for zero-warning enforcement."
          elif [[ "${{ steps.frontend-execution.outputs.lint_failure_type }}" == "missing" ]]; then
            echo "::warning title=Frontend Build - No Linting Configuration::No ESLint scripts found. Consider adding linting for code quality."
          else
            echo "::error title=Frontend Build Failed::Unknown build failure - check build logs for details."
          fi

          # Summary annotation
          echo "::notice title=Zero-Warning Build Policy::This project enforces zero ESLint warnings. Warning-as-error enforcement: ${{ steps.frontend-execution.outputs.warning_enforcement_active }}"

      - name: Upload frontend artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build-${{ github.run_number }}
          path: artifacts/frontend/
          retention-days: 7

  build-summary:
    name: "Build Summary"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build]
    if: always() && !cancelled()

    steps:
      - name: Generate build summary
        run: |
          echo "📊 Build Pipeline Summary"
          echo "========================"
          echo ""
          echo "**Path Analysis:**"
          echo "  - Backend changed: ${{ needs.path-analysis.outputs.backend-changed }}"
          echo "  - Frontend changed: ${{ needs.path-analysis.outputs.frontend-changed }}"
          echo "  - Documentation only: ${{ needs.path-analysis.outputs.docs-only }}"
          echo "  - Components: ${{ needs.path-analysis.outputs.changed-files }}"
          echo ""
          echo "**Build Results:**"
          echo "  - Backend build: ${{ needs.backend-build.result || 'skipped' }}"
          echo "  - Frontend build: ${{ needs.frontend-build.result || 'skipped' }}"
          echo ""

          # Check for failures
          if [ "${{ needs.backend-build.result }}" = "failure" ] || [ "${{ needs.frontend-build.result }}" = "failure" ]; then
            echo "❌ One or more builds failed"
            exit 1
          elif [ "${{ needs.path-analysis.outputs.docs-only }}" = "true" ]; then
            echo "📚 Only documentation changed - no builds required"
          else
            echo "✅ All required builds completed successfully"
          fi


  claude-standards-analysis:
    name: "Quality Analysis • Standards Compliance (AI)"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build, build-summary]
    if: always() && !cancelled() && github.event_name == 'pull_request' && contains(fromJSON('["main", "develop"]'), github.event.pull_request.base.ref) && (needs.build-summary.result == 'success' || needs.path-analysis.outputs.docs-only == 'true')
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Extract PR Context
        id: pr-context
        uses: ./.github/actions/shared/extract-pr-context

      - name: Check for existing Standards analysis comment
        id: check-existing-comment
        uses: ./.github/actions/shared/check-existing-comment
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          header: '## Code Review Report - Standards Compliance Analysis'

      - name: Create skip status check
        if: steps.check-existing-comment.outputs.skip_analysis == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('StandardsGuardian analysis skipped - existing unresolved analysis comment found');

      - name: Load standards compliance prompt
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: load-standards-prompt
        run: |
          # Read the markdown template
          PROMPT_TEMPLATE=$(cat .github/prompts/standards-compliance.md)

          # Replace placeholders with actual values
          PROMPT="${PROMPT_TEMPLATE//\{\{PR_NUMBER\}\}/${{ github.event.number }}}"
          PROMPT="${PROMPT//\{\{PR_AUTHOR\}\}/${{ github.event.pull_request.user.login }}}"
          PROMPT="${PROMPT//\{\{ISSUE_REF\}\}/${{ steps.pr-context.outputs.issue_ref }}}"
          PROMPT="${PROMPT//\{\{SOURCE_BRANCH\}\}/${{ github.event.pull_request.head.ref }}}"
          PROMPT="${PROMPT//\{\{TARGET_BRANCH\}\}/${{ github.event.pull_request.base.ref }}}"
          PROMPT="${PROMPT//\{\{CHANGED_FILES_COUNT\}\}/${{ steps.pr-context.outputs.changed_files_count }}}"
          PROMPT="${PROMPT//\{\{LINES_CHANGED\}\}/${{ steps.pr-context.outputs.lines_changed }}}"

          # Output for use in Claude action
          echo "prompt<<EOF" >> $GITHUB_OUTPUT
          echo "$PROMPT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Standards Compliance AI Analysis
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: claude-standards
        uses: grll/claude-code-action@beta
        with:
          use_oauth: true
          claude_access_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          claude_refresh_token: ${{ secrets.CLAUDE_REFRESH_TOKEN }}
          claude_expires_at: ${{ secrets.CLAUDE_EXPIRES_AT }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          direct_prompt: ${{ steps.load-standards-prompt.outputs.prompt }}

      - name: Handle Standards Analysis Failure
        if: failure() && steps.claude-standards.outcome == 'failure'
        uses: ./.github/actions/handle-ai-analysis-failure
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          analysis-type: 'StandardsGuardian'
          analysis-emoji: '🛡️'
          analysis-name: 'Standards Compliance Analysis'
          standards-link: 'https://github.com/Zarichney-Development/zarichney-api/blob/main/Docs/Standards/CodingStandards.md'
          run-number: ${{ github.run_number }}
          run-id: ${{ github.run_id }}

  claude-tech-debt-analysis:
    name: "Quality Analysis • Tech Debt Analysis (AI)"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build, build-summary]
    if: always() && !cancelled() && github.event_name == 'pull_request' && contains(fromJSON('["main", "develop"]'), github.event.pull_request.base.ref) && (needs.build-summary.result == 'success' || needs.path-analysis.outputs.docs-only == 'true')
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Extract PR Context
        id: pr-context
        uses: ./.github/actions/shared/extract-pr-context

      - name: Check for existing Tech Debt analysis comment
        id: check-existing-comment
        uses: ./.github/actions/shared/check-existing-comment
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          header: '## Code Review Report - Tech Debt Analysis'

      - name: Create skip status check
        if: steps.check-existing-comment.outputs.skip_analysis == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('DebtSentinel analysis skipped - existing unresolved analysis comment found');

      - name: Load tech debt analysis prompt
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: load-techdebt-prompt
        run: |
          # Read the markdown template
          PROMPT_TEMPLATE=$(cat .github/prompts/tech-debt-analysis.md)

          # Replace placeholders with actual values
          PROMPT="${PROMPT_TEMPLATE//\{\{PR_NUMBER\}\}/${{ github.event.number }}}"
          PROMPT="${PROMPT//\{\{PR_AUTHOR\}\}/${{ github.event.pull_request.user.login }}}"
          PROMPT="${PROMPT//\{\{ISSUE_REF\}\}/${{ steps.pr-context.outputs.issue_ref }}}"
          PROMPT="${PROMPT//\{\{SOURCE_BRANCH\}\}/${{ github.event.pull_request.head.ref }}}"
          PROMPT="${PROMPT//\{\{TARGET_BRANCH\}\}/${{ github.event.pull_request.base.ref }}}"
          PROMPT="${PROMPT//\{\{CHANGED_FILES_COUNT\}\}/${{ steps.pr-context.outputs.changed_files_count }}}"
          PROMPT="${PROMPT//\{\{LINES_CHANGED\}\}/${{ steps.pr-context.outputs.lines_changed }}}"

          # Output for use in Claude action
          echo "prompt<<EOF" >> $GITHUB_OUTPUT
          echo "$PROMPT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Tech Debt AI Analysis
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: claude-techdebt
        uses: grll/claude-code-action@beta
        with:
          use_oauth: true
          claude_access_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          claude_refresh_token: ${{ secrets.CLAUDE_REFRESH_TOKEN }}
          claude_expires_at: ${{ secrets.CLAUDE_EXPIRES_AT }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          direct_prompt: ${{ steps.load-techdebt-prompt.outputs.prompt }}

      - name: Handle Tech Debt Analysis Failure
        if: failure() && steps.claude-techdebt.outcome == 'failure'
        uses: ./.github/actions/handle-ai-analysis-failure
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          analysis-type: 'DebtSentinel'
          analysis-emoji: '🔍'
          analysis-name: 'Technical Debt Analysis'
          run-number: ${{ github.run_number }}
          run-id: ${{ github.run_id }}

  security-scans:
    name: "Security • Comprehensive Scanning"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build, build-summary]
    if: always() && !cancelled() && github.event_name == 'pull_request' && contains(fromJSON('["main", "epic/testing-coverage"]'), github.event.pull_request.base.ref) && (needs.build-summary.result == 'success' || needs.path-analysis.outputs.docs-only == 'true')
    timeout-minutes: 45

    strategy:
      fail-fast: false
      matrix:
        scan-type: ['codeql', 'dependencies', 'secrets', 'policy']

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup development environment
        if: matrix.scan-type == 'dependencies'
        uses: ./.github/actions/shared/setup-environment
        with:
          setup-dotnet: 'true'
          setup-node: 'true'
          dotnet-version: '8.0.x'
          node-version: '18.x'

      - name: Initialize CodeQL
        if: matrix.scan-type == 'codeql'
        continue-on-error: true
        uses: github/codeql-action/init@v3
        with:
          languages: 'csharp,javascript'
          config-file: ./.github/codeql/codeql-config.yml
          queries: security-extended,security-and-quality

      - name: Build for CodeQL
        if: matrix.scan-type == 'codeql'
        continue-on-error: true
        run: |
          # Build backend for CodeQL analysis (exclude test projects to avoid test-only compile errors)
          dotnet restore Code/Zarichney.Server/Zarichney.Server.csproj
          dotnet build Code/Zarichney.Server/Zarichney.Server.csproj --configuration Release --no-restore

          # Build frontend for CodeQL analysis
          cd Code/Zarichney.Website
          npm ci --legacy-peer-deps
          npm run build-prod

      - name: Perform CodeQL Analysis
        if: matrix.scan-type == 'codeql'
        continue-on-error: true
        id: codeql-analysis
        uses: github/codeql-action/analyze@v3

      - name: Report CodeQL Status
        if: matrix.scan-type == 'codeql'
        run: |
          if [ "${{ steps.codeql-analysis.outcome }}" = "failure" ]; then
            echo "::warning title=CodeQL Analysis::CodeQL analysis encountered issues but build continues. Check GitHub Security tab for findings."
            echo "::notice title=Security Advisory::CodeQL provides informational security feedback and does not block builds. Review findings in the Security tab for actionable insights."
            echo "📊 CodeQL Status: Failed (non-blocking)"
            echo "🔍 Action Required: Review findings in GitHub Security tab"
            echo "✅ Build Status: Continuing as CodeQL is advisory-only"
          else
            echo "::notice title=CodeQL Analysis::CodeQL analysis completed successfully. Results available in GitHub Security tab."
            echo "📊 CodeQL Status: Completed successfully"
            echo "🔍 Security Results: Available in GitHub Security tab"
          fi

      - name: Install required tools
        run: |
          echo "📦 Installing required tools for security scanning..."
          sudo apt-get update -qq
          sudo apt-get install -y jq

      - name: Run security scans
        run: |
          echo "🔒 Running security scanning pipeline..."
          echo "📊 Scan Type: ${{ matrix.scan-type }}"

          # Set environment variables
          export GITHUB_TOKEN="${{ secrets.GITHUB_TOKEN }}"
          export BASE_BRANCH="${{ github.event.pull_request.base.ref }}"
          export HEAD_SHA="${{ github.event.pull_request.head.sha }}"

          # Make scripts executable
          chmod +x ./.github/scripts/run-security-scans.sh
          chmod +x ./.github/scripts/*.sh

          # Execute security scanning based on matrix type
          case "${{ matrix.scan-type }}" in
            "codeql")
              echo "CodeQL analysis handled by GitHub Actions"
              echo "✅ CodeQL analysis completed successfully"
              exit 0
              ;;
            "dependencies")
              echo "🔍 Running dependency security scanning..."
              if ./.github/scripts/run-security-scans.sh --deps-only --skip-analysis; then
                echo "✅ Dependency scanning completed successfully"
                exit 0
              else
                echo "❌ Dependency scanning failed"
                exit 1
              fi
              ;;
            "secrets")
              echo "🔐 Running secrets detection scanning..."
              if ./.github/scripts/run-security-scans.sh --secrets-only --skip-analysis; then
                echo "✅ Secrets scanning completed successfully"
                exit 0
              else
                echo "❌ Secrets scanning failed"
                exit 1
              fi
              ;;
            "policy")
              echo "📋 Running policy compliance checks..."
              if ./.github/scripts/run-security-scans.sh --policy-only --skip-analysis; then
                echo "✅ Policy compliance checks completed successfully"
                exit 0
              else
                echo "❌ Policy compliance checks failed"
                exit 1
              fi
              ;;
            *)
              echo "❌ Unknown scan type: ${{ matrix.scan-type }}"
              exit 1
              ;;
          esac

      - name: Upload security scan results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-${{ matrix.scan-type }}-${{ github.run_number }}
          path: |
            security-analysis/
            artifacts/security/
          retention-days: 90

  claude-security-analysis:
    name: "Security • AI Analysis"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build, build-summary, security-scans]
    if: always() && !cancelled() && github.event_name == 'pull_request' && contains(fromJSON('["main"]'), github.event.pull_request.base.ref) && (needs.build-summary.result == 'success' || needs.path-analysis.outputs.docs-only == 'true')
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Extract PR Context
        id: pr-context
        uses: ./.github/actions/shared/extract-pr-context

      - name: Download all security scan results
        uses: actions/download-artifact@v4
        with:
          pattern: security-scan-*-${{ github.run_number }}
          path: security-results/
          merge-multiple: true

      - name: Create PR check run
        id: create-check
        run: |
          CHECK_RUN_ID=$(gh api repos/${{ github.repository }}/check-runs \
            --method POST \
            --field name="Security Analysis" \
            --field head_sha="${{ github.event.pull_request.head.sha }}" \
            --field status="in_progress" \
            --field details_url="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --jq '.id')
          echo "check_run_id=$CHECK_RUN_ID" >> $GITHUB_OUTPUT
          echo "Created check run ID: $CHECK_RUN_ID"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Check for existing Security analysis comment
        id: check-existing-comment
        uses: ./.github/actions/shared/check-existing-comment
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          header: '## Code Review Report - Security Analysis'

      - name: Create skip status check
        if: steps.check-existing-comment.outputs.skip_analysis == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('SecuritySentinel analysis skipped - existing unresolved analysis comment found');

      - name: Load security analysis prompt
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: load-security-prompt
        run: |
          # Read the markdown template
          PROMPT_TEMPLATE=$(cat .github/prompts/security-analysis.md)

          # Replace placeholders with actual values
          PROMPT="${PROMPT_TEMPLATE//\{\{PR_NUMBER\}\}/${{ github.event.number }}}"
          PROMPT="${PROMPT//\{\{PR_AUTHOR\}\}/${{ github.event.pull_request.user.login }}}"
          PROMPT="${PROMPT//\{\{ISSUE_REF\}\}/${{ steps.pr-context.outputs.issue_ref }}}"
          PROMPT="${PROMPT//\{\{SOURCE_BRANCH\}\}/${{ github.event.pull_request.head.ref }}}"
          PROMPT="${PROMPT//\{\{TARGET_BRANCH\}\}/${{ github.event.pull_request.base.ref }}}"
          PROMPT="${PROMPT//\{\{CHANGED_FILES_COUNT\}\}/${{ steps.pr-context.outputs.changed_files_count }}}"
          PROMPT="${PROMPT//\{\{LINES_CHANGED\}\}/${{ steps.pr-context.outputs.lines_changed }}}"

          # Output for use in Claude action
          echo "prompt<<EOF" >> $GITHUB_OUTPUT
          echo "$PROMPT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Security Analysis with Claude AI
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: claude-security
        uses: grll/claude-code-action@beta
        with:
          use_oauth: true
          claude_access_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          claude_refresh_token: ${{ secrets.CLAUDE_REFRESH_TOKEN }}
          claude_expires_at: ${{ secrets.CLAUDE_EXPIRES_AT }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          direct_prompt: ${{ steps.load-security-prompt.outputs.prompt }}

      - name: Handle Security Analysis Failure
        if: failure() && steps.claude-security.outcome == 'failure'
        uses: ./.github/actions/handle-ai-analysis-failure
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          analysis-type: 'SecuritySentinel'
          analysis-emoji: '🔒'
          analysis-name: 'Security Analysis'
          run-number: ${{ github.run_number }}
          run-id: ${{ github.run_id }}

      - name: Complete PR check run
        if: always() && steps.create-check.outputs.check_run_id != ''
        run: |
          # Determine security status based on scan results and skip conditions
          if [ "${{ steps.check-existing-comment.outputs.skip_analysis }}" = "true" ]; then
            CONCLUSION="success"
            TITLE="⏭️ Security Analysis: Skipped"
            SUMMARY="Security analysis skipped - existing unresolved analysis comment found in PR."
          elif [ "${{ steps.claude-security.outcome }}" = "success" ]; then
            CONCLUSION="success"
            TITLE="✅ Security Analysis: Completed Successfully"
            SUMMARY="Security analysis completed successfully. Check PR comments for detailed findings."
          elif [ "${{ steps.claude-security.outcome }}" = "failure" ]; then
            CONCLUSION="failure"
            TITLE="❌ Security Analysis: Failed"
            SUMMARY="Security analysis failed - check workflow logs and PR comments for details."
          elif [ "${{ job.status }}" = "failure" ]; then
            CONCLUSION="failure"
            TITLE="❌ Security Analysis: Critical Issues Found"
            SUMMARY="Critical security vulnerabilities detected - review required before deployment"
          else
            CONCLUSION="neutral"
            TITLE="🔒 Security Analysis: Completed"
            SUMMARY="Security analysis completed. Review findings in PR comments."
          fi

          gh api repos/${{ github.repository }}/check-runs/${{ steps.create-check.outputs.check_run_id }} \
            --method PATCH \
            --field status="completed" \
            --field conclusion="$CONCLUSION" \
            --field output[title]="$TITLE" \
            --field output[summary]="$SUMMARY"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload security analysis artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-analysis-${{ github.run_number }}
          path: security-results/
          retention-days: 90

  claude-merge-orchestrator:
    name: "Final Analysis • Merge Orchestrator (AI)"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build, build-summary, claude-testing-analysis, claude-standards-analysis, claude-tech-debt-analysis, security-scans, claude-security-analysis]
    if: always() && !cancelled() && github.event_name == 'pull_request' && contains(fromJSON('["main", "develop"]'), github.event.pull_request.base.ref) && (needs.build-summary.result == 'success' || needs.path-analysis.outputs.docs-only == 'true')
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Extract PR Context
        id: pr-context
        uses: ./.github/actions/shared/extract-pr-context

      - name: Check for existing PR Merge Review analysis comment
        id: check-existing-comment
        uses: ./.github/actions/shared/check-existing-comment
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          header: '## Code Review Report - PR Merge Review Analysis'

      - name: Create skip status check
        if: steps.check-existing-comment.outputs.skip_analysis == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            console.log('MergeOrchestrator analysis skipped - existing unresolved analysis comment found');

      - name: Load merge orchestrator prompt
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: load-orchestrator-prompt
        run: |
          # Read the markdown template
          PROMPT_TEMPLATE=$(cat .github/prompts/merge-orchestrator-analysis.md)

          # Replace placeholders with actual values
          PROMPT="${PROMPT_TEMPLATE//\\{\\{PR_NUMBER\\}\\}/${{ github.event.number }}}"
          PROMPT="${PROMPT//\\{\\{PR_AUTHOR\\}\\}/${{ github.event.pull_request.user.login }}}"
          PROMPT="${PROMPT//\\{\\{ISSUE_REF\\}\\}/${{ steps.pr-context.outputs.issue_ref }}}"
          PROMPT="${PROMPT//\\{\\{SOURCE_BRANCH\\}\\}/${{ github.event.pull_request.head.ref }}}"
          PROMPT="${PROMPT//\\{\\{TARGET_BRANCH\\}\\}/${{ github.event.pull_request.base.ref }}}"
          PROMPT="${PROMPT//\\{\\{CHANGED_FILES_COUNT\\}\\}/${{ steps.pr-context.outputs.changed_files_count }}}"
          PROMPT="${PROMPT//\\{\\{LINES_CHANGED\\}\\}/${{ steps.pr-context.outputs.lines_changed }}}"

          # Output for use in Claude action
          echo "prompt<<EOF" >> $GITHUB_OUTPUT
          echo "$PROMPT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Merge Orchestrator AI Analysis
        if: steps.check-existing-comment.outputs.skip_analysis != 'true'
        id: claude-orchestrator
        uses: grll/claude-code-action@beta
        with:
          use_oauth: true
          claude_access_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          claude_refresh_token: ${{ secrets.CLAUDE_REFRESH_TOKEN }}
          claude_expires_at: ${{ secrets.CLAUDE_EXPIRES_AT }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          direct_prompt: ${{ steps.load-orchestrator-prompt.outputs.prompt }}

      - name: Handle Merge Orchestrator Failure
        if: failure() && steps.claude-orchestrator.outcome == 'failure'
        uses: ./.github/actions/handle-ai-analysis-failure
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          analysis-type: 'MergeOrchestrator'
          analysis-emoji: '🎯'
          analysis-name: 'Merge Orchestrator Analysis'
          run-number: ${{ github.run_number }}
          run-id: ${{ github.run_id }}

  final-summary:
    name: "Pipeline Summary"
    runs-on: ubuntu-latest
    needs: [path-analysis, backend-build, frontend-build, build-summary, claude-testing-analysis, claude-standards-analysis, claude-tech-debt-analysis, security-scans, claude-security-analysis, claude-merge-orchestrator]
    if: always() && !cancelled()
    timeout-minutes: 5

    steps:
      - name: Generate comprehensive pipeline summary
        run: |
          echo "🚀 Zarichney API - Mega Build Pipeline Summary"
          echo "=============================================="
          echo ""
          echo "**Pipeline Configuration:**"
          echo "  - Trigger: ${{ github.event_name }}"
          echo "  - Branch: ${{ github.head_ref || github.ref_name }}"
          echo "  - Target: ${{ github.event.pull_request.base.ref || 'N/A' }}"
          echo "  - SHA: ${{ github.sha }}"
          echo ""

          echo "**Path Analysis:**"
          echo "  - Backend changed: ${{ needs.path-analysis.outputs.backend-changed || 'N/A' }}"
          echo "  - Frontend changed: ${{ needs.path-analysis.outputs.frontend-changed || 'N/A' }}"
          echo "  - Documentation only: ${{ needs.path-analysis.outputs.docs-only || 'N/A' }}"
          echo ""

          echo "**Build Results:**"
          echo "  - Backend build: ${{ needs.backend-build.result || 'skipped' }}"
          echo "  - Frontend build: ${{ needs.frontend-build.result || 'skipped' }}"
          echo "  - Build summary: ${{ needs.build-summary.result || 'skipped' }}"
          echo ""

          echo "**Quality Analysis Results:**"
          echo "  - Testing Analysis (AI): ${{ needs.claude-testing-analysis.result || 'skipped' }}"
          echo "  - Standards Analysis (AI): ${{ needs.claude-standards-analysis.result || 'skipped' }}"
          echo "  - Tech Debt Analysis (AI): ${{ needs.claude-tech-debt-analysis.result || 'skipped' }}"
          echo ""

          echo "**Security Analysis Results:**"
          echo "  - Security scans: ${{ needs.security-scans.result || 'skipped' }}"
          echo "  - Security Analysis (AI): ${{ needs.claude-security-analysis.result || 'skipped' }}"
          echo ""

          echo "**Final Analysis Results:**"
          echo "  - Merge Orchestrator (AI): ${{ needs.claude-merge-orchestrator.result || 'skipped' }}"
          echo ""

          # Determine overall pipeline status
          FAILED=false
          CRITICAL_FAILED=false

          # Check critical build jobs
          if [ "${{ needs.backend-build.result }}" = "failure" ] || [ "${{ needs.frontend-build.result }}" = "failure" ]; then
            CRITICAL_FAILED=true
            FAILED=true
          fi

          # Check if security analysis failed (non-critical)
          if [ "${{ needs.security-scans.result }}" = "failure" ]; then
            echo "⚠️  Analysis jobs failed but this does not block the pipeline"
          fi

          echo "**Branch-Specific Behavior:**"
          if [ "${{ github.event.pull_request.base.ref }}" = "main" ]; then
            echo "  🔒 Full pipeline with security analysis (PR to main)"
            echo "  🤖 All Claude AI analysis enabled (Testing + Standards + Tech Debt + Security + MergeOrchestrator)"
          elif [ "${{ github.event.pull_request.base.ref }}" = "develop" ]; then
            echo "  📊 Quality analysis pipeline (PR to develop)"
            echo "  🤖 Claude AI analysis enabled (Testing + Standards + Tech Debt + MergeOrchestrator)"
          else
            echo "  🏗️  Build-only pipeline (PR to non-main/develop branch)"
            echo "  🤖 No Claude AI analysis (not targeting main/develop)"
          fi
          echo ""

          # Final status determination
          if [ "$CRITICAL_FAILED" = "true" ]; then
            echo "❌ **PIPELINE FAILED**: Critical build failures detected"
            echo "🚫 **ACTION REQUIRED**: Fix build issues before proceeding"
            exit 1
          elif [ "$FAILED" = "true" ]; then
            echo "⚠️  **PIPELINE COMPLETED WITH WARNINGS**: Non-critical issues detected"
            echo "📝 **RECOMMENDED**: Review analysis results and address issues"
          else
            echo "✅ **PIPELINE SUCCEEDED**: All jobs completed successfully"
            if [ "${{ github.event.pull_request.base.ref }}" = "main" ] || [ "${{ github.event.pull_request.base.ref }}" = "develop" ]; then
              echo "🤖 **AI ANALYSIS**: Claude AI feedback available in PR comments"
            fi
            echo "🎉 **READY**: Changes are ready for review and merge"
          fi
