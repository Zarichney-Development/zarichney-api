name: Unified CI/CD for Zarichney Fullstack

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'Code/Zarichney.Server/**'
      - 'Code/Zarichney.Server.Tests/**'
      - 'Code/Zarichney.Website/**'
      - '*.sln'
      - 'Scripts/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'Code/Zarichney.Server/**'
      - 'Code/Zarichney.Server.Tests/**'
      - 'Code/Zarichney.Website/**'
      - '*.sln'
      - 'Scripts/**'
      - '.github/workflows/**'
  workflow_dispatch:

env:
  DOTNET_VERSION: '8.0.x'
  NODE_VERSION: '18.x'
  AWS_REGION: us-east-2
  SECRET_ID: cookbook-factory-secrets
  SECRET_DB_PASSWORD_KEY: DbPassword
  # Performance tracking
  BUILD_RUN_ID: ${{ github.run_id }}

# Pipeline Control Options:
# - Add 'skip-backend' label to PR to skip backend builds
# - Add 'skip-frontend' label to PR to skip frontend builds  
# - Add 'force-backend' label to PR to force backend builds
# - Add 'force-frontend' label to PR to force frontend builds
# - Include 'skip-frontend-deploy' in commit message to skip frontend deployment

permissions:
  id-token: write
  contents: read
  actions: read
  pull-requests: write  # Required for posting PR comments

jobs:
  backend_build_and_test:
    name: Backend - Build and Test
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'pull_request' && (contains(github.event.pull_request.labels.*.name, 'force-backend') || !contains(github.event.pull_request.labels.*.name, 'skip-backend'))) ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache .NET packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Install tools with retry
        run: |
          for i in {1..3}; do
            if dotnet tool update --global dotnet-ef --version 8.*; then
              break
            else
              echo "Attempt $i failed, retrying in 5 seconds..."
              sleep 5
            fi
          done
          dotnet tool restore

      - name: Restore dependencies with retry
        run: |
          for i in {1..3}; do
            if dotnet restore zarichney-api.sln; then
              break
            else
              echo "Restore attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done

      - name: Build
        run: dotnet build zarichney-api.sln --configuration Release --no-restore

      - name: Generate API Client
        run: |
          if [ -f "./Scripts/generate-api-client.sh" ]; then
            chmod +x ./Scripts/generate-api-client.sh
            ./Scripts/generate-api-client.sh
          else
            pwsh ./Scripts/generate-api-client.ps1
          fi

      - name: Advanced Test Execution with Quality Gates
        run: |
          echo "🚀 Running unified test suite with AI-powered analysis..."
          
          # Make unified script executable
          chmod +x ./Scripts/run-test-suite.sh
          
          # Set quality gate thresholds
          export COVERAGE_THRESHOLD=24  # Current baseline, targeting 90%
          export QUALITY_GATE_ENABLED=true
          export CI_ENVIRONMENT=true
          
          # Run comprehensive test suite with JSON output for CI/CD using unified script
          # Phase 3: Enable parallel execution for faster CI/CD feedback
          if ./Scripts/run-test-suite.sh report json --threshold=24 --parallel --max-parallel-collections=4; then
            echo "✅ All tests passed and quality gates met"
          else
            echo "❌ Tests failed or quality gates not met"
            exit 1
          fi

      - name: Parse and validate test results
        if: always()
        run: |
          echo "📊 Analyzing test results for quality gate validation..."
          
          if [ -f "./TestResults/parsed_results.json" ]; then
            echo "Test results found, extracting metrics..."
            
            # Extract key metrics for quality gates
            TOTAL_TESTS=$(jq -r '.tests.total // 0' ./TestResults/parsed_results.json)
            FAILED_TESTS=$(jq -r '.tests.failed // 0' ./TestResults/parsed_results.json)
            PASS_RATE=$(jq -r '.tests.pass_rate // 0' ./TestResults/parsed_results.json)
            
            echo "📈 Test Metrics:"
            echo "  Total Tests: $TOTAL_TESTS"
            echo "  Failed Tests: $FAILED_TESTS"
            echo "  Pass Rate: $PASS_RATE%"
            
            # Quality gate enforcement
            if [ "$FAILED_TESTS" -gt 0 ]; then
              echo "❌ Quality Gate FAILED: $FAILED_TESTS test(s) are failing"
              exit 1
            fi
            
            if [ "$PASS_RATE" -lt 95 ]; then
              echo "⚠️  Quality Gate WARNING: Pass rate ($PASS_RATE%) below 95%"
            fi
            
            echo "✅ Quality gates validated successfully"
          else
            echo "❌ No test results found - pipeline failure"
            exit 1
          fi

      - name: Upload enhanced test artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: advanced-test-results-${{ github.run_id }}
          path: |
            ./TestResults/**/*.trx
            ./TestResults/**/*.json
            ./TestResults/**/*.md
            ./TestResults/**/*.log
          retention-days: 30

      - name: Upload coverage results with trend analysis
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-analysis-${{ github.run_id }}
          path: |
            ./TestResults/**/coverage.cobertura.xml
            ./TestResults/coverage_results.json
          retention-days: 30
      
      - name: Upload Phase 3 Advanced Analytics
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: phase3-analytics-${{ github.run_id }}
          path: |
            ./TestResults/dynamic_quality_gates.json
            ./TestResults/trend_analysis.json
            ./TestResults/deployment_risk.json
            ./TestResults/regression_analysis.json
            ./TestResults/historical/**/*.json
          retention-days: 30

      - name: Prepare Test Data for AI Analysis
        if: always()
        run: |
          echo "📊 Preparing test data for Claude AI analysis..."
          
          # Check if we have test results to analyze
          if [ ! -f "./TestResults/parsed_results.json" ] || [ ! -f "./TestResults/coverage_results.json" ]; then
            echo "⚠️ Missing test result files - creating empty data for analysis"
            echo '{"tests":{"total":0,"passed":0,"failed":0,"skipped":0,"pass_rate":0}}' > ./TestResults/parsed_results.json
            echo '{"line_coverage":0,"branch_coverage":0,"meets_threshold":false}' > ./TestResults/coverage_results.json
          fi
          
          # Extract key metrics for AI analysis
          TOTAL_TESTS=$(jq -r '.tests.total // 0' ./TestResults/parsed_results.json)
          PASSED_TESTS=$(jq -r '.tests.passed // 0' ./TestResults/parsed_results.json)
          FAILED_TESTS=$(jq -r '.tests.failed // 0' ./TestResults/parsed_results.json)
          SKIPPED_TESTS=$(jq -r '.tests.skipped // 0' ./TestResults/parsed_results.json)
          PASS_RATE=$(jq -r '.tests.pass_rate // 0' ./TestResults/parsed_results.json)
          
          LINE_COVERAGE=$(jq -r '.line_coverage // 0' ./TestResults/coverage_results.json)
          BRANCH_COVERAGE=$(jq -r '.branch_coverage // 0' ./TestResults/coverage_results.json)
          MEETS_THRESHOLD=$(jq -r '.meets_threshold // false' ./TestResults/coverage_results.json)
          
          # Check if quality gates failed
          QUALITY_GATES_STATUS="PASSED"
          if [ -f "./TestResults/quality_status.env" ]; then
            source ./TestResults/quality_status.env
            if [ "${QUALITY_GATES_FAILED:-false}" == "true" ]; then
              QUALITY_GATES_STATUS="FAILED"
            fi
          fi
          
          # Create comprehensive test analysis data for Claude
          cat > ./TestResults/claude_analysis_data.json << EOF
          {
            "project": "zarichney-api",
            "analysis_type": "test_execution_and_coverage_analysis",
            "build_context": {
              "branch": "${{ github.ref_name }}",
              "commit_sha": "${{ github.sha }}",
              "event_type": "${{ github.event_name }}",
              "run_id": "${{ github.run_id }}",
              "actor": "${{ github.actor }}",
              "timestamp": "$(date -Iseconds)"
            },
            "test_metrics": {
              "total_tests": $TOTAL_TESTS,
              "passed_tests": $PASSED_TESTS,
              "failed_tests": $FAILED_TESTS,
              "skipped_tests": $SKIPPED_TESTS,
              "pass_rate_percentage": $PASS_RATE
            },
            "coverage_metrics": {
              "line_coverage_percentage": $LINE_COVERAGE,
              "branch_coverage_percentage": $BRANCH_COVERAGE,
              "meets_coverage_threshold": $MEETS_THRESHOLD,
              "coverage_threshold": 24
            },
            "quality_gates": {
              "overall_status": "$QUALITY_GATES_STATUS",
              "has_failing_tests": $([ "$FAILED_TESTS" -gt 0 ] && echo "true" || echo "false"),
              "coverage_below_threshold": $([ "$MEETS_THRESHOLD" = "true" ] && echo "false" || echo "true")
            },
            "deployment_readiness": {
              "deployment_blocked": $([ "$QUALITY_GATES_STATUS" = "FAILED" ] && echo "true" || echo "false"),
              "risk_level": "$([ "$FAILED_TESTS" -gt 0 ] && echo "HIGH" || ([ "$MEETS_THRESHOLD" = "false" ] && echo "MEDIUM" || echo "LOW"))"
            }
          }
          EOF
          
          echo "✅ Test data prepared for AI analysis"
          echo "  - Tests: $PASSED_TESTS/$TOTAL_TESTS passed ($PASS_RATE% pass rate)"
          echo "  - Coverage: $LINE_COVERAGE% lines, $BRANCH_COVERAGE% branches"
          echo "  - Quality Gates: $QUALITY_GATES_STATUS"

      - name: Real Claude AI Test Analysis (Max Subscription)
        if: always()
        uses: anthropics/claude-code-action@beta
        with:
          oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          direct_prompt: |
            # Expert Test Analysis for zarichney-api Project
            
            You are a senior software quality engineer conducting a comprehensive analysis of test execution results and code coverage for the zarichney-api project.
            
            ## Analysis Data
            Please analyze the test data in `./TestResults/claude_analysis_data.json` which contains:
            - Test execution metrics (passed, failed, skipped tests)
            - Code coverage percentages (line and branch coverage)
            - Quality gate status and deployment readiness
            - Build context and metadata
            
            ## Required Analysis Sections
            
            ### 1. Executive Summary
            - Overall test suite health assessment (Excellent/Good/Fair/Poor/Critical)
            - Key achievements and immediate concerns
            - Deployment risk level (Low/Medium/High/Critical) with reasoning
            
            ### 2. Test Execution Analysis
            - Test pass rate trends and patterns
            - Analysis of failed tests (if any) and their potential impact
            - Evaluation of skipped tests and missing coverage
            - Performance and reliability assessment
            
            ### 3. Coverage Quality Assessment
            - Coverage adequacy beyond just percentages
            - Identification of critical uncovered code paths
            - Coverage quality vs quantity evaluation
            - Comparison against industry standards and project goals
            
            ### 4. Quality Gates Compliance
            - Current quality gate status and implications
            - Recommendations for quality gate improvements
            - Risk assessment for deployment based on current metrics
            
            ### 5. Actionable Recommendations
            **Priority ranked by impact:**
            - Immediate actions required before deployment
            - Short-term improvements (next sprint)
            - Long-term quality strategy enhancements
            - Specific test areas requiring attention with file paths
            
            ### 6. Risk Assessment & Deployment Decision
            - Production deployment safety evaluation
            - Potential issues to monitor post-deployment
            - Rollback scenarios and contingency planning
            - Final deployment recommendation (DEPLOY/BLOCK/CONDITIONAL)
            
            ## Output Requirements
            - Generate response in clear, actionable markdown
            - Be specific about file paths, test categories, and concrete steps
            - Include technical details suitable for senior developers
            - Provide confidence levels for your recommendations
            - Reference specific metrics from the analysis data
            
            Your analysis will be posted as a PR comment and used for deployment decisions.

      - name: Create Deployment Decision File
        if: always()
        run: |
          echo "💾 Creating deployment decision based on analysis..."
          
          # Extract metrics for deployment decision
          TOTAL_TESTS=$(jq -r '.test_metrics.total_tests // 0' ./TestResults/claude_analysis_data.json)
          FAILED_TESTS=$(jq -r '.test_metrics.failed_tests // 0' ./TestResults/claude_analysis_data.json)
          QUALITY_GATES_STATUS=$(jq -r '.quality_gates.overall_status // "UNKNOWN"' ./TestResults/claude_analysis_data.json)
          MEETS_THRESHOLD=$(jq -r '.coverage_metrics.meets_coverage_threshold // false' ./TestResults/claude_analysis_data.json)
          
          # Create deployment decision file for other jobs
          cat > ./TestResults/deployment_decision.json << EOF
          {
            "deploy_recommended": $([ "$QUALITY_GATES_STATUS" = "PASSED" ] && echo "true" || echo "false"),
            "risk_level": "$([ "$FAILED_TESTS" -gt 0 ] && echo "HIGH" || ([ "$MEETS_THRESHOLD" = "false" ] && echo "MEDIUM" || echo "LOW"))",
            "quality_gates_passed": $([ "$QUALITY_GATES_STATUS" = "PASSED" ] && echo "true" || echo "false"),
            "analysis_timestamp": "$(date -Iseconds)",
            "ai_analysis_completed": true,
            "total_tests": $TOTAL_TESTS,
            "failed_tests": $FAILED_TESTS
          }
          EOF
          
          echo "✅ Deployment decision file created"

  frontend_build:
    name: Frontend - Build
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'pull_request' && (contains(github.event.pull_request.labels.*.name, 'force-frontend') || !contains(github.event.pull_request.labels.*.name, 'skip-frontend'))) ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')
    timeout-minutes: 15
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: Code/Zarichney.Website/package-lock.json

      - name: Install Frontend Dependencies with retry
        run: |
          cd ./Code/Zarichney.Website
          for i in {1..3}; do
            if npm ci --legacy-peer-deps; then
              break
            else
              echo "npm install attempt $i failed, retrying in 10 seconds..."
              sleep 10
              npm cache clean --force || true
              rm -rf node_modules package-lock.json || true
            fi
          done

      - name: Build Frontend for Production
        run: npm run build-prod
        working-directory: ./Code/Zarichney.Website
        
      - name: Display build summary
        run: |
          echo "✅ Frontend build completed successfully"
          echo "Build artifacts created:"
          ls -la dist/
          echo "Bundle sizes:"
          du -sh dist/browser/* | head -10
        working-directory: ./Code/Zarichney.Website
        
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build-artifacts
          path: |
            Code/Zarichney.Website/dist/
            Code/Zarichney.Website/package.json
            Code/Zarichney.Website/package-lock.json
            Code/Zarichney.Website/scripts/
          retention-days: 1

  frontend_deploy:
    name: Frontend - Deploy
    runs-on: ubuntu-latest
    needs: frontend_build
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main' && !contains(github.event.push.head_commit.message, 'skip-frontend-deploy'))
    timeout-minutes: 20
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: frontend-build-artifacts
          path: ./Code/Zarichney.Website/
          
      - name: Display deployment info
        run: |
          echo "🚀 Starting frontend deployment"
          echo "Build artifacts downloaded:"
          ls -la ./Code/Zarichney.Website/dist/
          echo "Deployment target: Production (S3 + EC2)"

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-Frontend-${{ github.run_id }}

      - name: Deploy static assets to S3 with retry
        run: |
          for i in {1..3}; do
            if aws s3 sync dist/browser s3://static.zarichney.com --delete; then
              echo "S3 sync successful"
              break
            else
              echo "S3 sync attempt $i failed, retrying in 15 seconds..."
              sleep 15
            fi
          done
        working-directory: ./Code/Zarichney.Website

      - name: Prepare server files for EC2
        run: |
          mkdir -p server-deploy/scripts
          cp -r dist/server/* server-deploy/
          cp package.json package-lock.json server-deploy/
          cp -r scripts/* server-deploy/scripts/
        working-directory: ./Code/Zarichney.Website

      - name: Deploy Frontend to EC2 with enhanced error handling
        env:
          EC2_HOST: ${{ secrets.EC2_HOST_FRONTEND }}
          EC2_USERNAME: ec2-user
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
        run: |
          echo "$EC2_SSH_KEY" > private_key && chmod 600 private_key
          
          # Deploy files with retry
          for i in {1..3}; do
            if scp -r -o StrictHostKeyChecking=no -o ConnectTimeout=30 -i private_key ./server-deploy/* ${EC2_USERNAME}@${EC2_HOST}:~/app/; then
              echo "File deployment successful"
              break
            else
              echo "File deployment attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done
          
          # Deploy application with enhanced error handling
          ssh -o StrictHostKeyChecking=no -o ConnectTimeout=30 -i private_key ${EC2_USERNAME}@${EC2_HOST} 'bash -s' <<'EOF'
            set -e
            cd ~/app
            
            echo "Installing dependencies..."
            npm ci --omit=dev --legacy-peer-deps
            
            echo "Restarting application..."
            if pm2 list | grep -q "server"; then
              pm2 restart server
            else
              pm2 start "npm run serve:ssr" --name server
            fi
            
            echo "Waiting for application to start..."
            sleep 5
            
            # Verify PM2 process is running
            if pm2 list | grep -q "server.*online"; then
              echo "Application started successfully"
            else
              echo "Application failed to start properly"
              pm2 logs server --lines 10
              exit 1
            fi
          EOF
        working-directory: ./Code/Zarichney.Website

      - name: Health check frontend deployment
        run: |
          echo "Performing health check on frontend..."
          for i in {1..5}; do
            if curl -f -s -o /dev/null --max-time 30 https://zarichney.com; then
              echo "Frontend health check passed"
              break
            else
              echo "Health check attempt $i failed, waiting 15 seconds..."
              sleep 15
            fi
          done

      - name: Invalidate CloudFront for Frontend
        run: |
          for i in {1..3}; do
            if aws cloudfront create-invalidation --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} --paths "/*"; then
              echo "CloudFront invalidation successful"
              break
            else
              echo "CloudFront invalidation attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done

  backend_deploy:
    name: Backend - Deploy
    needs: backend_build_and_test
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')
    timeout-minutes: 20
      
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Cache .NET packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Install EF Core Tools with retry
        run: |
          for i in {1..3}; do
            if dotnet tool update --global dotnet-ef --version 8.*; then
              break
            else
              echo "EF Tools install attempt $i failed, retrying in 5 seconds..."
              sleep 5
            fi
          done

      - name: Generate EF Migrations Script
        run: |
          mkdir -p ./publish/migrations
          dotnet ef migrations script --context UserDbContext --project Code/Zarichney.Server/Zarichney.Server.csproj -o ./publish/migrations/ApplyAllMigrations.sql --idempotent

      - name: Publish Application
        run: dotnet publish Code/Zarichney.Server/Zarichney.Server.csproj -c Release -o ./publish

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_OIDC_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-Backend-${{ github.run_id }}

      - name: Deploy Backend to EC2 and Apply Migrations with enhanced error handling
        env:
          EC2_HOST: ${{ secrets.EC2_HOST_BACKEND }}
          EC2_USERNAME: ec2-user
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
        run: |
          echo "$EC2_SSH_KEY" > private_key && chmod 600 private_key
          
          # Deploy files with retry
          for i in {1..3}; do
            if scp -r -o StrictHostKeyChecking=no -o ConnectTimeout=30 -i private_key ./publish/* ${EC2_USERNAME}@${EC2_HOST}:/opt/cookbook-api/; then
              echo "Backend file deployment successful"
              break
            else
              echo "Backend file deployment attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done

          ssh -o StrictHostKeyChecking=no -o ConnectTimeout=30 -i private_key ${EC2_USERNAME}@${EC2_HOST} 'bash -s' <<'EOF'
            set -e # Exit on error
            
            echo "Attempting to retrieve DB password from Secrets Manager..."
            for i in {1..3}; do
              DB_PASSWORD=$(aws secretsmanager get-secret-value --secret-id "${{ env.SECRET_ID }}" --region "${{ env.AWS_REGION }}" --query SecretString --output text | jq -r '.${{ env.SECRET_DB_PASSWORD_KEY }}' 2>/dev/null)
              
              if [ -n "$DB_PASSWORD" ] && [ "$DB_PASSWORD" != "null" ]; then
                echo "Database password retrieved successfully"
                break
              else
                echo "DB password retrieval attempt $i failed, retrying in 5 seconds..."
                sleep 5
              fi
            done
            
            if [ -z "$DB_PASSWORD" ] || [ "$DB_PASSWORD" == "null" ]; then
              echo "ERROR: Failed to retrieve database password after retries."
              exit 1
            fi
            
            export PGPASSWORD="$DB_PASSWORD"
            
            echo "Applying database migrations..."
            cd /opt/cookbook-api/Server/Auth/Migrations
            chmod +x ./ApplyMigrations.sh
            
            # Run migrations with timeout
            timeout 180s ./ApplyMigrations.sh || {
              echo "Migration failed or timed out"
              unset PGPASSWORD
              exit 1
            }
            
            unset PGPASSWORD
            echo "Migrations applied successfully."
            
            echo "Restarting cookbook-api service..."
            if sudo systemctl is-active --quiet cookbook-api; then
              sudo systemctl restart cookbook-api
            else
              sudo systemctl start cookbook-api
            fi
            
            echo "Waiting for service to start..."
            sleep 10
            
            # Verify service is running
            for i in {1..6}; do
              if sudo systemctl is-active --quiet cookbook-api; then
                echo "Backend service is running successfully"
                break
              else
                echo "Service check attempt $i failed, waiting 10 seconds..."
                sleep 10
              fi
            done
            
            if ! sudo systemctl is-active --quiet cookbook-api; then
              echo "Service failed to start properly"
              sudo systemctl status cookbook-api
              sudo journalctl -u cookbook-api --lines 20
              exit 1
            fi
          EOF

      - name: Health check backend deployment
        run: |
          echo "Performing health check on backend API..."
          for i in {1..8}; do
            if curl -f -s -o /dev/null --max-time 30 https://api.zarichney.com/health || curl -f -s -o /dev/null --max-time 30 https://api.zarichney.com/status; then
              echo "Backend health check passed"
              break
            else
              echo "Health check attempt $i failed, waiting 15 seconds..."
              sleep 15
            fi
          done

      - name: Invalidate CloudFront for Backend
        run: |
          for i in {1..3}; do
            if aws cloudfront create-invalidation --distribution-id ${{ secrets.CLOUDFRONT_DISTRIBUTION_ID }} --paths "/api/*"; then
              echo "Backend CloudFront invalidation successful"
              break
            else
              echo "Backend CloudFront invalidation attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done