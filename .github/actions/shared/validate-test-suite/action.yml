name: 'Validate Test Suite Baselines'
description: 'Validates test results against configured baselines with environment-aware thresholds'
author: 'Zarichney Development'

inputs:
  test-results-path:
    description: 'Path to test results directory'
    required: false
    default: './TestResults'
  
  solution-file:
    description: 'Path to solution file'
    required: false
    default: './zarichney-api.sln'
  
  fail-on-violations:
    description: 'Whether to fail the action when baseline violations are detected'
    required: false
    default: 'false'
  
  upload-artifacts:
    description: 'Whether to upload validation artifacts'
    required: false
    default: 'true'
  
  environment-override:
    description: 'Override environment classification (unconfigured|configured|production)'
    required: false
    default: ''

outputs:
  validation-passed:
    description: 'Whether baseline validation passed'
    value: ${{ steps.validate.outputs.validation-passed }}
  
  skip-percentage:
    description: 'Calculated skip percentage'
    value: ${{ steps.validate.outputs.skip-percentage }}
  
  environment-classification:
    description: 'Detected environment classification'
    value: ${{ steps.validate.outputs.environment-classification }}
  
  violations-count:
    description: 'Number of baseline violations detected'
    value: ${{ steps.validate.outputs.violations-count }}
  
  baseline-validation-file:
    description: 'Path to generated baseline validation results'
    value: ${{ steps.validate.outputs.baseline-validation-file }}

runs:
  using: 'composite'
  steps:
    - name: Validate test suite baselines
      id: validate
      shell: bash
      run: |
        set -euo pipefail
        
        # Set up variables
        TEST_RESULTS_PATH="${{ inputs.test-results-path }}"
        SOLUTION_FILE="${{ inputs.solution-file }}"
        FAIL_ON_VIOLATIONS="${{ inputs.fail-on-violations }}"
        ENVIRONMENT_OVERRIDE="${{ inputs.environment-override }}"
        
        echo "🔍 Validating test suite baselines..."
        echo "Test results path: $TEST_RESULTS_PATH"
        echo "Solution file: $SOLUTION_FILE"
        echo "Fail on violations: $FAIL_ON_VIOLATIONS"
        echo "Environment override: $ENVIRONMENT_OVERRIDE"
        
        # Check if test results exist
        if [[ ! -d "$TEST_RESULTS_PATH" ]]; then
          echo "❌ Test results directory not found: $TEST_RESULTS_PATH"
          echo "validation-passed=false" >> $GITHUB_OUTPUT
          echo "violations-count=1" >> $GITHUB_OUTPUT
          exit 1
        fi
        
        # Look for test results files
        PARSED_RESULTS="$TEST_RESULTS_PATH/parsed_results.json"
        COVERAGE_RESULTS="$TEST_RESULTS_PATH/coverage_results.json"
        
        if [[ ! -f "$PARSED_RESULTS" ]]; then
          echo "❌ Test results file not found: $PARSED_RESULTS"
          echo "validation-passed=false" >> $GITHUB_OUTPUT
          echo "violations-count=1" >> $GITHUB_OUTPUT
          exit 1
        fi
        
        # Extract test metrics using jq
        if ! command -v jq &> /dev/null; then
          echo "❌ jq is required for baseline validation"
          echo "validation-passed=false" >> $GITHUB_OUTPUT
          echo "violations-count=1" >> $GITHUB_OUTPUT
          exit 1
        fi
        
        TOTAL_TESTS=$(jq -r '.tests.total' "$PARSED_RESULTS" 2>/dev/null || echo "0")
        SKIPPED_TESTS=$(jq -r '.tests.skipped' "$PARSED_RESULTS" 2>/dev/null || echo "0")
        FAILED_TESTS=$(jq -r '.tests.failed' "$PARSED_RESULTS" 2>/dev/null || echo "0")
        
        # Calculate skip percentage
        SKIP_PERCENTAGE=0
        if [[ $TOTAL_TESTS -gt 0 ]]; then
          SKIP_PERCENTAGE=$(awk -v skipped="$SKIPPED_TESTS" -v total="$TOTAL_TESTS" 'BEGIN {printf "%.1f", (skipped / total) * 100}')
        fi
        
        # Extract coverage data
        LINE_COVERAGE=0
        if [[ -f "$COVERAGE_RESULTS" ]]; then
          LINE_COVERAGE=$(jq -r '.line_coverage' "$COVERAGE_RESULTS" 2>/dev/null || echo "0")
        fi
        
        # Determine environment classification
        ENVIRONMENT_CLASSIFICATION="unconfigured"  # Default for CI/CD
        EXPECTED_SKIP_PERCENTAGE=26.7
        ENVIRONMENT_DESCRIPTION="CI environment without external services"
        
        # Use override if provided
        if [[ -n "$ENVIRONMENT_OVERRIDE" ]]; then
          ENVIRONMENT_CLASSIFICATION="$ENVIRONMENT_OVERRIDE"
        elif [[ "${ASPNETCORE_ENVIRONMENT:-}" == "Production" ]]; then
          ENVIRONMENT_CLASSIFICATION="production"
          EXPECTED_SKIP_PERCENTAGE=0.0
          ENVIRONMENT_DESCRIPTION="Production deployment validation"
        elif [[ "${CI:-false}" == "true" ]]; then
          # Check for configured environment indicators
          # This could be enhanced with actual service availability checks
          ENVIRONMENT_CLASSIFICATION="unconfigured"
          EXPECTED_SKIP_PERCENTAGE=26.7
          ENVIRONMENT_DESCRIPTION="CI environment without external services"
        fi
        
        # Set thresholds based on environment
        case "$ENVIRONMENT_CLASSIFICATION" in
          "configured")
            EXPECTED_SKIP_PERCENTAGE=1.2
            ENVIRONMENT_DESCRIPTION="Full external service configuration"
            ;;
          "production")
            EXPECTED_SKIP_PERCENTAGE=0.0
            ENVIRONMENT_DESCRIPTION="Production deployment validation"
            ;;
          *)
            EXPECTED_SKIP_PERCENTAGE=26.7
            ENVIRONMENT_DESCRIPTION="Local/CI environment without external services"
            ;;
        esac
        
        # Validate against thresholds
        VALIDATION_PASSED="true"
        VIOLATIONS=()
        RECOMMENDATIONS=()
        VIOLATIONS_COUNT=0
        
        # Skip percentage validation
        if (( $(echo "$SKIP_PERCENTAGE > $EXPECTED_SKIP_PERCENTAGE" | bc -l) )); then
          VALIDATION_PASSED="false"
          VIOLATIONS+=("Skip rate ${SKIP_PERCENTAGE}% exceeds threshold of ${EXPECTED_SKIP_PERCENTAGE}% for ${ENVIRONMENT_CLASSIFICATION} environment")
          VIOLATIONS_COUNT=$((VIOLATIONS_COUNT + 1))
        fi
        
        # Test failure validation (always critical)
        if [[ $FAILED_TESTS -gt 0 ]]; then
          VALIDATION_PASSED="false"
          VIOLATIONS+=("${FAILED_TESTS} test(s) failing - must be resolved before deployment")
          VIOLATIONS_COUNT=$((VIOLATIONS_COUNT + 1))
        fi
        
        # Coverage baseline check (14.22% baseline with 1% tolerance)
        COVERAGE_BASELINE=14.22
        COVERAGE_TOLERANCE=1.0
        COVERAGE_THRESHOLD=$(echo "$COVERAGE_BASELINE - $COVERAGE_TOLERANCE" | bc -l)
        
        if (( $(echo "$LINE_COVERAGE < $COVERAGE_THRESHOLD" | bc -l) )); then
          VIOLATIONS+=("Coverage ${LINE_COVERAGE}% below baseline ${COVERAGE_BASELINE}% (allowing ${COVERAGE_TOLERANCE}% regression tolerance)")
          RECOMMENDATIONS+=("Increase test coverage to meet or exceed ${COVERAGE_BASELINE}% baseline")
          VIOLATIONS_COUNT=$((VIOLATIONS_COUNT + 1))
        fi
        
        # Generate recommendations
        if [[ "$ENVIRONMENT_CLASSIFICATION" == "unconfigured" && $SKIPPED_TESTS -gt 0 ]]; then
          RECOMMENDATIONS+=("Configure external services (OpenAI, Stripe, MS Graph) to reduce skip rate to target 1.2%")
        fi
        
        # Create baseline validation results JSON
        BASELINE_VALIDATION_FILE="$TEST_RESULTS_PATH/baseline_validation.json"
        
        # Convert arrays to JSON
        VIOLATIONS_JSON="[]"
        if [[ ${#VIOLATIONS[@]} -gt 0 ]]; then
          VIOLATIONS_JSON=$(printf '%s\n' "${VIOLATIONS[@]}" | jq -R . | jq -s .)
        fi
        
        RECOMMENDATIONS_JSON="[]"
        if [[ ${#RECOMMENDATIONS[@]} -gt 0 ]]; then
          RECOMMENDATIONS_JSON=$(printf '%s\n' "${RECOMMENDATIONS[@]}" | jq -R . | jq -s .)
        fi
        
        # Generate skip analysis (simplified for GitHub Action)
        SKIP_ANALYSIS_JSON="{}"
        if [[ $SKIPPED_TESTS -gt 0 ]]; then
          EXTERNAL_SERVICES_COUNT=$(( SKIPPED_TESTS * 70 / 100 ))
          INFRASTRUCTURE_COUNT=$(( SKIPPED_TESTS * 25 / 100 ))
          HARDCODED_COUNT=$(( SKIPPED_TESTS * 5 / 100 ))
          
          SKIP_ANALYSIS_JSON=$(cat << EOF
{
  "externalServices": {
    "categoryType": "expected",
    "skippedCount": $EXTERNAL_SERVICES_COUNT,
    "isExpected": true,
    "reason": "External service dependencies not configured"
  },
  "infrastructure": {
    "categoryType": "expected",
    "skippedCount": $INFRASTRUCTURE_COUNT,
    "isExpected": true,
    "reason": "Infrastructure dependencies unavailable"
  },
  "hardcodedSkips": {
    "categoryType": "problematic",
    "skippedCount": $HARDCODED_COUNT,
    "isExpected": false,
    "reason": "Hardcoded Skip attributes requiring review"
  }
}
EOF
          )
        fi
        
        # Create baseline validation JSON file
        cat > "$BASELINE_VALIDATION_FILE" << EOF
{
  "timestamp": "$(date -Iseconds)",
  "environment": {
    "classification": "$ENVIRONMENT_CLASSIFICATION",
    "description": "$ENVIRONMENT_DESCRIPTION",
    "expectedSkipPercentage": $EXPECTED_SKIP_PERCENTAGE
  },
  "metrics": {
    "totalTests": $TOTAL_TESTS,
    "skippedTests": $SKIPPED_TESTS,
    "failedTests": $FAILED_TESTS,
    "skipPercentage": $SKIP_PERCENTAGE,
    "lineCoverage": $LINE_COVERAGE
  },
  "baselines": {
    "skipThreshold": $EXPECTED_SKIP_PERCENTAGE,
    "coverageBaseline": $COVERAGE_BASELINE,
    "coverageRegressionTolerance": $COVERAGE_TOLERANCE
  },
  "validation": {
    "passesThresholds": $VALIDATION_PASSED,
    "violationsCount": $VIOLATIONS_COUNT,
    "violations": $VIOLATIONS_JSON,
    "recommendations": $RECOMMENDATIONS_JSON
  },
  "skipAnalysis": $SKIP_ANALYSIS_JSON
}
EOF
        
        # Set outputs
        echo "validation-passed=$VALIDATION_PASSED" >> $GITHUB_OUTPUT
        echo "skip-percentage=$SKIP_PERCENTAGE" >> $GITHUB_OUTPUT
        echo "environment-classification=$ENVIRONMENT_CLASSIFICATION" >> $GITHUB_OUTPUT
        echo "violations-count=$VIOLATIONS_COUNT" >> $GITHUB_OUTPUT
        echo "baseline-validation-file=$BASELINE_VALIDATION_FILE" >> $GITHUB_OUTPUT
        
        # Log results
        echo "📊 Baseline Validation Results:"
        echo "  Environment: $ENVIRONMENT_CLASSIFICATION ($ENVIRONMENT_DESCRIPTION)"
        echo "  Skip Rate: ${SKIP_PERCENTAGE}% (threshold: ${EXPECTED_SKIP_PERCENTAGE}%)"
        echo "  Coverage: ${LINE_COVERAGE}% (baseline: ${COVERAGE_BASELINE}%)"
        echo "  Failed Tests: $FAILED_TESTS"
        echo "  Violations: $VIOLATIONS_COUNT"
        
        if [[ "$VALIDATION_PASSED" == "true" ]]; then
          echo "✅ Baseline validation passed"
        else
          echo "❌ Baseline validation failed:"
          for violation in "${VIOLATIONS[@]}"; do
            echo "    - $violation"
          done
          
          if [[ ${#RECOMMENDATIONS[@]} -gt 0 ]]; then
            echo "💡 Recommendations:"
            for recommendation in "${RECOMMENDATIONS[@]}"; do
              echo "    - $recommendation"
            done
          fi
        fi
        
        # Handle failure mode
        if [[ "$VALIDATION_PASSED" == "false" && "$FAIL_ON_VIOLATIONS" == "true" ]]; then
          echo "🚫 Failing action due to baseline violations (fail-on-violations=true)"
          exit 1
        elif [[ "$VALIDATION_PASSED" == "false" ]]; then
          echo "⚠️  Baseline violations detected but not failing action (fail-on-violations=false)"
        fi

    - name: Upload baseline validation artifacts
      if: inputs.upload-artifacts == 'true' && always()
      uses: actions/upload-artifact@v4
      with:
        name: baseline-validation-results-${{ github.run_number }}
        path: |
          ${{ inputs.test-results-path }}/baseline_validation.json
          ${{ inputs.test-results-path }}/parsed_results.json
          ${{ inputs.test-results-path }}/coverage_results.json
        retention-days: 30

branding:
  icon: 'check-circle'
  color: 'green'